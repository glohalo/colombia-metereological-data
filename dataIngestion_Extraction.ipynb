{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22546d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the basic libraries we will require for the project\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "\n",
    "#importing global\n",
    "import glob\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "\n",
    "# Code to ignore warnings from function usage\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820259ac",
   "metadata": {},
   "source": [
    "# Concatenation of meteorological variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59668c",
   "metadata": {},
   "source": [
    "In the next section historicals sensors measurement for each meteorological variable data will be concatenated in one big \"csv\" file. The data is originally stored in \".data\" files. A \".data\" file is a separate file by \"\n",
    "The file is namened by as follows:BSHG_TT_D@10000000.data\n",
    "- BSHG_TT_D, corresponds of the variable name tag\n",
    "- 10000000, code station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "090d66a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concatenating all the files in a list. One variable at a time\n",
    "path ='/Users/yourdatapath'\n",
    "file_list = glob.glob(path+\"/*.data\")\n",
    "# list of .data files we want to merge.\n",
    "data_list = []\n",
    "station_list = []\n",
    "for file in file_list:\n",
    "    _df=pd.read_csv(file, sep=\"|\")\n",
    "    data_list.append(_df)\n",
    "    station_list.extend(repeat(int(os.path.basename(file).split('/')[-1].split('@')[-1].split('.')[0]), len(_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f46786bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the list\n",
    "#data usta is a list of three data per row\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "91b2ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the len of the lists \n",
    "print({'station len':len(station_list), 'data len': len(data_list)}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c4e20",
   "metadata": {},
   "source": [
    "In this step the code_station list will be stored as a \"dataframe\" and then concatenated with data_list. Repeat this step for each folder, for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c951faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeStation = pd.DataFrame({'Codigo': station_list})\n",
    "metereological_var = pd.concat([pd.concat(data_list, axis=0, ignore_index=True), codeStation], axis=1)\n",
    "#saving the file in csv format\n",
    "metereological_var.to_csv('/yourpath/metereological_var_all.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ee8c5",
   "metadata": {},
   "source": [
    "## Making match of the code station\n",
    "\n",
    "In this section the measurement of each code station will be asigned to its region, department, altitude, longitude and latitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9a348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data file of \"national code of stations\"\n",
    "data_station= pd.read_excel('datapath/CNE_IDEAM.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74642818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the desired variables\n",
    "dataStation_filtered= data_station[['CODIGO', 'altitud', 'longitud','latitud', 'DEPARTAMENTO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1fd75",
   "metadata": {},
   "source": [
    "### Standarizing the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4993f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping dictionary for replacements\n",
    "replacement_mapping = {\n",
    "    'Caqueta': 'Caquetá',\n",
    "    'RIsaralda': 'Risaralda',\n",
    "    'Atlantico': 'Atlántico',\n",
    "    'Vaupes': 'Vaupés',\n",
    "    'Choco': 'Chocó',\n",
    "    'Antioquía': 'Antioquia',\n",
    "    'Guania': 'Guainía',\n",
    "    'Norte de santander': 'Norte de Santander'\n",
    "}\n",
    "\n",
    "# Apply the replacements in a single pass\n",
    "dataStation_filtered['DEPARTAMENTO'] = dataStation_filtered['DEPARTAMENTO'].replace(replacement_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35ff289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO</th>\n",
       "      <th>altitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>latitud</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>25020230</td>\n",
       "      <td>170</td>\n",
       "      <td>-73.339472</td>\n",
       "      <td>9.562167</td>\n",
       "      <td>Cesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>26170150</td>\n",
       "      <td>1819</td>\n",
       "      <td>-75.838806</td>\n",
       "      <td>5.791056</td>\n",
       "      <td>Antioquia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>23177020</td>\n",
       "      <td>75</td>\n",
       "      <td>-73.983333</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>Antioquia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>52010150</td>\n",
       "      <td>2450</td>\n",
       "      <td>-76.588972</td>\n",
       "      <td>2.292750</td>\n",
       "      <td>Cauca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>33055010</td>\n",
       "      <td>167</td>\n",
       "      <td>-69.803333</td>\n",
       "      <td>4.494722</td>\n",
       "      <td>Vichada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CODIGO  altitud   longitud   latitud DEPARTAMENTO\n",
       "2445  25020230      170 -73.339472  9.562167        Cesar\n",
       "2031  26170150     1819 -75.838806  5.791056    Antioquia\n",
       "3231  23177020       75 -73.983333  7.166667    Antioquia\n",
       "1888  52010150     2450 -76.588972  2.292750        Cauca\n",
       "1867  33055010      167 -69.803333  4.494722      Vichada"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a sample of the data, to check the content\n",
    "dataStation_filtered.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7933d4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODIGO          0\n",
       "altitud         0\n",
       "longitud        0\n",
       "latitud         0\n",
       "DEPARTAMENTO    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "dataStation_filtered.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba91f23",
   "metadata": {},
   "source": [
    "### Categorizing regions based on the 'DEPARTAMENTO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d1ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assgning to each department the region\n",
    "region_caribe = ['Atlántico', 'Bolívar', 'Cesar', 'Magdalena', 'La Guajira', 'Sucre', 'Córdoba']\n",
    "region_andina = ['Bogotá','Antioquia', 'Caldas', 'Norte de Santander', 'Quindío', 'Risaralda', 'Santander', 'Boyacá', 'Cundinamarca', 'Tolima', 'Huila']\n",
    "region_amazonas = ['Amazonas', 'Caquetá', 'Guainía', 'Putumayo', 'Guaviare', 'Vaupés']\n",
    "region_pacifica = [ 'Cauca', 'Chocó', 'Nariño', 'Valle del Cauca']\n",
    "region_orinoquia = ['Arauca', 'Casanare', 'Meta', 'Vichada']\n",
    "providencia = ['Archipiélago de San Andres, Providencia y Santa Catalina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab5e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to make match\n",
    "def matchDepartment(x):\n",
    "    if x in region_amazonas :\n",
    "        return 'Amazonas'\n",
    "    elif x in region_andina :\n",
    "        return 'Andina'\n",
    "    elif x in region_caribe:\n",
    "        return 'Caribe'         \n",
    "    elif x in region_pacifica:\n",
    "        return 'Pacifica'\n",
    "    elif x in region_orinoquia:\n",
    "        return 'Orinoquía'\n",
    "    elif x in providencia:\n",
    "        return 'Insular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c854b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStation_filtered[\"Region\"] = dataStation_filtered['DEPARTAMENTO'].apply(matchDepartment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0a7ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODIGO          0\n",
       "altitud         0\n",
       "longitud        0\n",
       "latitud         0\n",
       "DEPARTAMENTO    0\n",
       "Region          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "dataStation_filtered.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a54f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reaming \"DEPARTAMENTO\",\"CODIGO\" to lowercase\n",
    "dataStation_filtered=dataStation_filtered.rename(columns={'DEPARTAMENTO':'Departamento', 'CODIGO':'Codigo'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85e3aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving sations code\n",
    "dataStation_filtered.to_csv('yourdatapatha/dataStation_filtered.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc43d0",
   "metadata": {},
   "source": [
    "### Reading the data to add to each stations its geographicals coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for input and output directories\n",
    "input_directory = 'yourpath/'\n",
    "output_directory = 'yourdatapath/'\n",
    "# Define a list of variables\n",
    "variables = ['brillosolar', 'nubosidad', 'velviento', 'temperatura', 'dirviento', 'rocio','humedadrelativa', \n",
    "             'fetatmosferico', 'evaporacion', 'precipitacion', 'recorridoviento', 'tensionvapor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stations data\n",
    "stations = pd.read_csv('yourdatapatha/dataStation_filtered.csv')\n",
    "stations = stations[stations['Codigo'].notnull()].set_index('Codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3fe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over each variable\n",
    "for var in variables:\n",
    "    input_file_path = os.path.join(input_directory, f'{var}_all.csv')\n",
    "    output_file_path = os.path.join(output_directory, f'{var}_location.csv')\n",
    "\n",
    "    # Read the CSV file with datetime parsing\n",
    "    df = pd.read_csv(input_file_path, parse_dates=['Datetime'])\n",
    "\n",
    "    # Filter datetime data from the year 2012\n",
    "    df = df[df['Datetime'].dt.year >= 2012]\n",
    "\n",
    "    # Filter rows with non-null 'Codigo' values\n",
    "    df = df[df['Codigo'].notnull()].set_index('Codigo')\n",
    "\n",
    "    # Join with stations data\n",
    "    df = stations.join(df, how='right')\n",
    "\n",
    "    # Save the result to a CSV file\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    # Clear the dataframe to release memory\n",
    "    del df\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
